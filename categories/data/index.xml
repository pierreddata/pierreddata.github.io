<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Data on Le D de Data</title>
        <link>https://blog.ddata.fr/categories/data/</link>
        <description>Recent content in Data on Le D de Data</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>fr-fr</language>
        <lastBuildDate>Sun, 26 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.ddata.fr/categories/data/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Datalake : la base d&#39;un projet data moderne</title>
        <link>https://blog.ddata.fr/p/datalake-la-base/</link>
        <pubDate>Sun, 26 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://blog.ddata.fr/p/datalake-la-base/</guid>
        <description>&lt;img src="https://blog.ddata.fr/p/datalake-la-base/ticka-kao-o87vASD6Ksk-unsplash.jpg" alt="Featured image of post Datalake : la base d&#39;un projet data moderne" /&gt;&lt;p&gt;Dans cet article je vous présente le concept de Datalake ou lac de données en bon français. Un datalake est la fondation d&amp;rsquo;un projet data moderne, vous le retrouverez dans la plupart de vos futurs projets.&lt;/p&gt;
&lt;h2 id=&#34;contexte&#34;&gt;Contexte&lt;/h2&gt;
&lt;p&gt;Comme je vous l&amp;rsquo;ai présenté &lt;a class=&#34;link&#34; href=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/&#34; &gt;dans ce précédent article&lt;/a&gt;, le datalake est un élément clé des projets data moderne. Je me propose maintenant de vous présenter plus en détail ce qu&amp;rsquo;est un datalake, comment on le structure et comment on peut s&amp;rsquo;en servir.&lt;br&gt;
Contrairement à ce que l&amp;rsquo;on pourrait croire, les datalakes ne sont pas réservés aux gros projets de data et leur philosophie d&amp;rsquo;usage peut-être reprise dans tout projet data.&lt;/p&gt;
&lt;h2 id=&#34;le-stockage&#34;&gt;Le stockage&lt;/h2&gt;
&lt;p&gt;Lorsque l&amp;rsquo;on parle datalake on parle avant tout d&amp;rsquo;un stockage de données pouvant accepter tout type de format de données.&lt;br&gt;
En général lorsque l&amp;rsquo;on parle de datalake on pense stockage cloud, l&amp;rsquo;avantage de ce type de stockage est sa capacité à être étendue en fonction de vos besoins et de vos finances. Bien que cette solution est la plus souple, on peut très bien créer un datalake en dehors du cloud.&lt;br&gt;
Les principaux types de stockages pour vos datalakes peuvent être :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;En cloud dans l&amp;rsquo;écosystème Microsoft
&lt;ul&gt;
&lt;li&gt;Azure Datalake Gen 2&lt;/li&gt;
&lt;li&gt;Sharepoint&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sur vos infrastructures locales
&lt;ul&gt;
&lt;li&gt;Un partage réseau&lt;/li&gt;
&lt;li&gt;Un disque dur&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lorganisation&#34;&gt;L&amp;rsquo;organisation&lt;/h2&gt;
&lt;p&gt;Une fois la solution de stockage choisie, il est indispensable de réfléchir à l&amp;rsquo;organisation de votre datalake.&lt;br&gt;
Sans rigueur votre lac de données deviendra un marais de données (dataswamp).&lt;/p&gt;
&lt;h3 id=&#34;les-zones&#34;&gt;Les zones&lt;/h3&gt;
&lt;p&gt;Bien que chacun puisse créer l&amp;rsquo;organisation qu&amp;rsquo;il souhaite, on retrouve en général les 3 zones suivantes :&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-la-base/img/001-datalake-zone.png&#34;
	width=&#34;799&#34;
	height=&#34;230&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-la-base/img/001-datalake-zone_hu727fac40be1e93915e54196ea9c46c88_7320_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-la-base/img/001-datalake-zone_hu727fac40be1e93915e54196ea9c46c88_7320_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Les zones d&amp;rsquo;un datalake&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;347&#34;
		data-flex-basis=&#34;833px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bronze : Cette zone sert de landing zone pour les données, elle permet d&amp;rsquo;écrire les données brutes reçues dans le datalake. Aucune transformation n&amp;rsquo;est réalisée sur les données.&lt;/li&gt;
&lt;li&gt;Silver : cette zone permet de raffiner les données de la zone Bronze et d&amp;rsquo;effectuer les traitements de préparation de données parmi lesquels on retrouve :
&lt;ul&gt;
&lt;li&gt;La transformation de données en un format de table avec
&lt;ul&gt;
&lt;li&gt;Le nommage des colonnes&lt;/li&gt;
&lt;li&gt;Le typage des colonnes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;La détection des anomalies&lt;/li&gt;
&lt;li&gt;La détection des problèmes de qualité&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gold : cette zone contient les données avec le plus haut niveau de raffinage, on retrouve par exemple
&lt;ul&gt;
&lt;li&gt;Des données modélisées pour le reporting (modèle en étoile).&lt;/li&gt;
&lt;li&gt;Des données préaggrégées.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Le nom de ces zones peut varier, mais leur usage reste. D&amp;rsquo;autres zones peuvent être créées en fonction de vos besoins spécifiques, par exemple une zone sandbox pour des expérimentations.&lt;/p&gt;
&lt;p&gt;Les coûts de stockage étant relativement bas, en général, les traitements permettant le raffinage des données d&amp;rsquo;une zone à l&amp;rsquo;autre ne suppriment pas les données traitées. Ainsi si vous traitez des données sources en utilisant 10 champs sur 50 dans le fichier brut et que vos besoins évoluent, vous aurez toujours la possibilité de retraiter l&amp;rsquo;ensemble des données brut pour répondre à vos nouveaux besoins.&lt;/p&gt;
&lt;h3 id=&#34;les-partitions&#34;&gt;Les partitions&lt;/h3&gt;
&lt;p&gt;Le partitionnement des données va vous permettre de ranger vos données de manière précise. Quand on parle de partitionnement, il s&amp;rsquo;agit simplement de mettre vos fichiers dans des dossiers et sous dossier différent. L&amp;rsquo;avantage du partitionnement est notamment de pouvoir accéder rapidement à des données en ne lisant que les fichiers présents dans les partitions qui nous intéressent.&lt;br&gt;
Vous pouvez mixer les partitions comme vous le souhaitez.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-la-base/img/002-datalake-partition.png&#34;
	width=&#34;774&#34;
	height=&#34;436&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-la-base/img/002-datalake-partition_hu0016a9332b0f3ada4911fd5db105c496_15833_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-la-base/img/002-datalake-partition_hu0016a9332b0f3ada4911fd5db105c496_15833_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Exemple de partitions&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;En général, on crée des partitions en créant des  dossiers sous la forme &lt;em&gt;NomPartition=ValeurPartition&lt;/em&gt;.&lt;br&gt;
Les principaux partitionnements que vous utiliserez sont :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Par source de données avec par exemple des dossiers sous la forme &lt;em&gt;/service=rh/application=monapplication&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Par version de traitement ou de format de fichier avec par exemple des dossiers sous la forme &lt;em&gt;/version=2.0&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Par date avec par exemple des dossiers sous la forme &lt;em&gt;/year=2023/month=02/day=26&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;les-principaux-formats-de-données&#34;&gt;Les principaux formats de données&lt;/h2&gt;
&lt;p&gt;Votre datalake va contenir des fichiers, voici quelque format classique que vous y trouverez :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parquet : C&amp;rsquo;est le format roi des datalakes, il s&amp;rsquo;agit d&amp;rsquo;un format de fichier dédier aux données analytiques, il conserve le nom et le type de données des colonnes et compresse les données contenues dans le fichier.&lt;/li&gt;
&lt;li&gt;CSV : Format classique d&amp;rsquo;extraction de données, il contient le nom des colonnes, mais les séparateurs utilisés peuvent varier en fonction de l&amp;rsquo;origine régionale du fichier (les séparateurs US et FR sont différents).&lt;/li&gt;
&lt;li&gt;Excel : Est-ce besoin de le présenter ? Un incontournable dans tous projets data.&lt;/li&gt;
&lt;li&gt;json, yaml, xml : Il s&amp;rsquo;agit en général de fichiers issus de traitement automatisé tel des API. Ces fichiers sont semi-structuré.&lt;/li&gt;
&lt;li&gt;log : les fichiers de log pourront être stockés longtemps et conserver une possibilité de traitement dans un datalake. Ces fichiers sont en général semi-structuré.&lt;/li&gt;
&lt;li&gt;Binaire : les vidéos et images sont des formats de données binaires, ils peuvent contenir certaines métadonnées exploitables directement (coordonnée GPS pour une photo par exemple), mais en général un traitement de type IA et nécessaire pour qualifier le contenu du fichier.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;la-sécurité&#34;&gt;La sécurité&lt;/h2&gt;
&lt;p&gt;La sécurité est un point clé de votre datalake, elle est portée par les possibilités offertes par la solution de stockage que vous avez choisie.&lt;br&gt;
Dans tous les cas, penser à créer plusieurs datalakes si vous avez des besoins forts de sécurité, une séparation des données peut prémunir contre des niveaux de droits inadéquats accordés à certain utilisateur.&lt;/p&gt;
&lt;h2 id=&#34;traitement-des-données&#34;&gt;Traitement des données&lt;/h2&gt;
&lt;p&gt;Le traitement des données d&amp;rsquo;un datalake fera l&amp;rsquo;objet d&amp;rsquo;un prochain article.&lt;/p&gt;
&lt;p&gt;Merci de votre attention.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Datawarehouse ou datalakehouse, quelle source pour vos reportings ?</title>
        <link>https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/</link>
        <pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/</guid>
        <description>&lt;img src="https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/antoine-petitteville-RIdYHUISNuM-unsplash.jpg" alt="Featured image of post Datawarehouse ou datalakehouse, quelle source pour vos reportings ?" /&gt;&lt;p&gt;Dans cet article, je vous présente les différentes sources possibles pour vos reportings. Les solutions natives de vos applications, un datawarehouse ou un datalakehouse ? Je vous propose de passer en revue ces solutions.&lt;/p&gt;
&lt;h2 id=&#34;le-reporting-de-données-sans-la-bi&#34;&gt;Le reporting de données sans la BI&lt;/h2&gt;
&lt;p&gt;Vos applications sont en général fournies avec des possibilités de reporting dédié fournies par l&amp;rsquo;éditeur de la solution.&lt;/p&gt;
&lt;p&gt;Les avantages de ces solutions de reporting natives sont principalement :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Le coût normalement inclut dans la solution.&lt;/li&gt;
&lt;li&gt;Des rapports en lien très fort avec les données de la solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Par contre les inconvénients sont en général :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Une faible capacité de customisation et d&amp;rsquo;intégration de règle spécifique à votre usage.&lt;/li&gt;
&lt;li&gt;L&amp;rsquo;impossibilité de croiser avec d&amp;rsquo;autres sources de données extérieures à la solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Si l’on faisait une analogie avec la cuisine, nous avons affaire à un plat industriel prêt à être consommé.&lt;/p&gt;
&lt;p&gt;On peut donc représenter cette solution avec le schéma ci-dessous avec des applications en silo qui délivre des rapports aux utilisateurs via des outils de reporting différents les uns des autres.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/001-data-sans-bi.png&#34;
	width=&#34;601&#34;
	height=&#34;706&#34;
	srcset=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/001-data-sans-bi_hu8a19905e549f9e1eaa5a52d8f8030dd9_33837_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/001-data-sans-bi_hu8a19905e549f9e1eaa5a52d8f8030dd9_33837_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Le reporting sans BI&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;85&#34;
		data-flex-basis=&#34;204px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;la-bi-à-la-rescousse-&#34;&gt;La BI à la rescousse !&lt;/h2&gt;
&lt;p&gt;Comment faire mieux que cette solution de données en silo ? La réponse est simplement l&amp;rsquo;informatique décisionnelle souvent appelée BI acronyme de son nom anglais Business Inteligence.&lt;/p&gt;
&lt;p&gt;L&amp;rsquo;objectif de la BI est de vous permettre d&amp;rsquo;utiliser un seul outil pour tous vos reportings, basé sur une source de données consolidées permettant le croisement des données de vos différents silos de données grâce à la mise en relation des données communes.&lt;/p&gt;
&lt;h2 id=&#34;les-services-attendus-dune-couche-data&#34;&gt;Les services attendus d&amp;rsquo;une couche data&lt;/h2&gt;
&lt;p&gt;Pour réaliser cet objectif, les solutions proposées par la BI ont évoluée dans le temps, mais les services attendus par cette couche intermédiaire reste les mêmes :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Capacité de traitement et de stockage dédié distinct de l&amp;rsquo;infrastructure de l&amp;rsquo;application&lt;/li&gt;
&lt;li&gt;Centralisation des données&lt;/li&gt;
&lt;li&gt;Modélisation des données optimisée pour le reporting (modèle en étoile)&lt;/li&gt;
&lt;li&gt;Historisation des données
&lt;ul&gt;
&lt;li&gt;Pour certaine dimension, il est nécessaire de conserver la trace des changements, on parle en général de dimension à variation lente (Slow changing dimension).&lt;/li&gt;
&lt;li&gt;Pour certaines tables de faits, comme les stocks, on souhaite conserver des photos à un instant T des données afin de les assembler en un film de données permettant de suivre l&amp;rsquo;évolution des changements dans le temps.&lt;/li&gt;
&lt;li&gt;Réaliser des transformations des données sources comme par exemple passées de données cumulées (non agrégable) en données journalière (agrégable).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cette liste n&amp;rsquo;est pas exhaustive des services attendus par les datatrucs.&lt;/p&gt;
&lt;h2 id=&#34;les-datawarehouses&#34;&gt;Les datawarehouses&lt;/h2&gt;
&lt;p&gt;La solution que l&amp;rsquo;on retrouve le plus fréquemment dans les solutions BI historiques des entreprises est le datawarehouse ou entrepôt de données en bon français.&lt;/p&gt;
&lt;p&gt;Un datawarehouse est basiquement une base de données dédiée au reporting. Cette base de données est chargée via un ETL (acronyme d&amp;rsquo;Extract Transform Load). Le chargement est en général réalisé par des traitements en mode batch, en opposition à un traitement en temps réel, qui charge les données à une fréquence prédéfinies, classiquement une fois par jour.&lt;/p&gt;
&lt;p&gt;Les données subissent des transformations lors du chargement afin que les tables résultantes soient optimisées pour le reporting, on passe en général d&amp;rsquo;une modélisation OLTP (celle de l&amp;rsquo;application) à une modélisation en étoile.&lt;/p&gt;
&lt;p&gt;Les datawarehouses sont des projets techniques en général réalisés par l&amp;rsquo;IT de l&amp;rsquo;entreprise.&lt;/p&gt;
&lt;p&gt;Si l’on faisait une analogie avec la cuisine, nous avons affaire à un plat fait maison, mais l&amp;rsquo;œuf utilisé pour la tarte ne peut plus servir à faire des crêpes.&lt;/p&gt;
&lt;p&gt;On peut donc représenter cette solution avec le schéma ci-dessous avec des applications en silo qui sont chargées dans une base intermédiaire dédié au reporting, le datawarehouse.&lt;br&gt;
Le reporting peut être réalisé par un outil unique  ou pas en fonction des besoins des utilisateurs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/002-datawarehouse.png&#34;
	width=&#34;578&#34;
	height=&#34;675&#34;
	srcset=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/002-datawarehouse_hu65ec1f30ab54919c049d7a2243557acb_25785_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/002-datawarehouse_hu65ec1f30ab54919c049d7a2243557acb_25785_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Le reporting avec un datawarehouse&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;85&#34;
		data-flex-basis=&#34;205px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;les-datalakehouses&#34;&gt;Les datalakehouses&lt;/h2&gt;
&lt;p&gt;Les datawarehouses ont certains inconvénients et ne sont pas optimisés pour répondre à certains besoins modernes :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Les données étant stockées dans une base de données, ils supportent très mal les données non structurées et les changements de structure des données dans le temps.&lt;/li&gt;
&lt;li&gt;Les données de type streaming (données en temps réel comme un capteur ou flux de données twitter) sont difficiles à intégrer dans un datawarehouse.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pour répondre à ces besoins modernes tout en gardant les services fournis par les datawarehouses, la BI moderne propose comme réponse les datalakehouses.&lt;/p&gt;
&lt;p&gt;Un datalakehouse est la fusion des datalakes et des datawarehouses. J&amp;rsquo;ai expliqué ce qu&amp;rsquo;est un datawarehouse ci-dessus, je vais donc expliqué le concept de datalake.&lt;/p&gt;
&lt;p&gt;Les datalakes sont la réponse au stockage de données répondant aux critères suivants :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Il accepte les formats multiples
&lt;ul&gt;
&lt;li&gt;Données structurées en provenance des bases de données&lt;/li&gt;
&lt;li&gt;Données semis structuré comme des fichiers Excel, JSON, CSV&lt;/li&gt;
&lt;li&gt;Données non structurées comme des images ou vidéos, qui pourront subir des traitements de type IA pour en extraire de l&amp;rsquo;information exploitable.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Il supporte des fréquences de chargement variables allant du mode batch de datawarehouse au temps réel.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ce stockage permettant tous ces cas d&amp;rsquo;usages n&amp;rsquo;est ni plus ni moins qu&amp;rsquo;un stockage avec les mêmes services qu&amp;rsquo;un disque dur, mais disponible en général dans le cloud.&lt;/p&gt;
&lt;p&gt;Le plus important avec un datalake est la rigueur avec laquelle on range ces données afin de ne pas finir avec un dataswamp ou marais de données.&lt;/p&gt;
&lt;p&gt;Un datalakehouse est donc une architecture de raffinage de données composé d&amp;rsquo;un datalake et de divers outils permettant le raffinage des données. Différents outils peuvent être utilisés aux différentes phases de raffinage en fonction des besoins.&lt;/p&gt;
&lt;p&gt;Les principales étapes de raffinage des données sont :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L&amp;rsquo;alimentation du datalake avec les données brutes, sans transformation, dans une zone que l&amp;rsquo;on nomme couramment &lt;em&gt;Bronze&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Le raffinage des données brut à l&amp;rsquo;aide de divers traitements en fonction des besoins, on stocke le résultat dans une zone que l&amp;rsquo;on nomme couramment &lt;em&gt;Silver&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;La mise à disposition des données de reporting dans une zone que l&amp;rsquo;on nomme couramment &lt;em&gt;Gold&lt;/em&gt;. Les données peuvent par exemple être préaggrégées pour améliorer le reporting.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On conserve les données de chaque étape ainsi on peut, si besoin, ajouter de nouveaux traitements sur d&amp;rsquo;anciennes données.&lt;br&gt;
Les données du datalake du dalakehouse seront donc disponibles pour d&amp;rsquo;autres usages tels que :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Du machine learning.&lt;/li&gt;
&lt;li&gt;Un référentiel d&amp;rsquo;entreprise mis à disposition d&amp;rsquo;autres applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Si l’on faisait une analogie avec la cuisine, nous avons affaire à un garde-manger où on en prend les éléments que l&amp;rsquo;on souhaite cuisiner en fonction des besoins.&lt;/p&gt;
&lt;p&gt;On peut donc représenter cette solution avec le schéma ci-dessous avec des applications en silo qui sont chargées dans un stockage intermédiaire sans usage spécifique puis préparé en fonction des besoins, notamment le reporting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/003-datalakehouse.png&#34;
	width=&#34;589&#34;
	height=&#34;754&#34;
	srcset=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/003-datalakehouse_hu24dae463978d3b0f2f8d47f596271f5e_31506_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/img/003-datalakehouse_hu24dae463978d3b0f2f8d47f596271f5e_31506_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Le reporting avec un datalakehouse&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;78&#34;
		data-flex-basis=&#34;187px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;J&amp;rsquo;espère que maintenant vous comprenez mieux l&amp;rsquo;utilisation de ces différents datatrucs.&lt;/p&gt;
&lt;p&gt;Merci de votre attention.&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
