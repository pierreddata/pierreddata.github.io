<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Azure on Le D de Data</title>
        <link>https://blog.ddata.fr/categories/azure/</link>
        <description>Recent content in Azure on Le D de Data</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>fr-fr</language>
        <lastBuildDate>Sun, 05 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.ddata.fr/categories/azure/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Datalake : comment traiter les données d&#39;un datalake dans Azure</title>
        <link>https://blog.ddata.fr/p/datalake-compute/</link>
        <pubDate>Sun, 05 Mar 2023 00:00:00 +0000</pubDate>
        
        <guid>https://blog.ddata.fr/p/datalake-compute/</guid>
        <description>&lt;img src="https://blog.ddata.fr/p/datalake-compute/deepmind-ZJKE4XVlKIA-unsplash.jpg" alt="Featured image of post Datalake : comment traiter les données d&#39;un datalake dans Azure" /&gt;&lt;p&gt;Dans cet article je vous présente les principaux services permettant de traiter les données d&amp;rsquo;un datalake dans Azure.&lt;/p&gt;
&lt;h2 id=&#34;rappel&#34;&gt;Rappel&lt;/h2&gt;
&lt;p&gt;Vous trouverez dans mes articles précédents les explications concernant :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Les architectures de type datalakehouse : &lt;a class=&#34;link&#34; href=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/&#34; &gt;Datawarehouse ou datalakehouse, quelle source pour vos reportings ?&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Les datalakes :&lt;a class=&#34;link&#34; href=&#34;https://blog.ddata.fr/p/datalake-la-base/&#34; &gt;Datalake : la base d&amp;rsquo;un projet data moderne&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;les-services-de-données-spécialisés&#34;&gt;Les services de données spécialisés&lt;/h2&gt;
&lt;h3 id=&#34;img10126-icon-service-data-factorypng-azure-data-factory&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/10126-icon-service-Data-Factory.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/10126-icon-service-Data-Factory_hu8e9af3290ac174282009dd85995d7eea_896_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/10126-icon-service-Data-Factory_hu8e9af3290ac174282009dd85995d7eea_896_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Data Factory&lt;/h3&gt;
&lt;p&gt;Azure Data Factory est un outil de type ETL/ELT (Extract Transform Load / Extract Load Transform), il permet de réaliser des déplacements de données d&amp;rsquo;un point à un autre en réalisant des transformations sur les données. Parmi les usages classiques, on retrouve :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alimentation de la zone Bronze d&amp;rsquo;un datalake avec des données en provenance de service cloud et de vos réseaux d&amp;rsquo;entreprise (via un programme installé sur vos serveurs)&lt;/li&gt;
&lt;li&gt;Transformation et structuration des données :
&lt;ul&gt;
&lt;li&gt;Création de fichiers structurés de type Parquet&lt;/li&gt;
&lt;li&gt;Re modélisation des données applicative vers un modèle en étoile&lt;/li&gt;
&lt;li&gt;Transformation de données semi-structurées de type JSON en données structuré de type Parquet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Suivi de l&amp;rsquo;exécution des traitements de transformation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/data-factory/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;img00606-icon-service-azure-synapse-analyticspng-azure-synapse-analytics&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/00606-icon-service-Azure-Synapse-Analytics.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/00606-icon-service-Azure-Synapse-Analytics_hu8e9af3290ac174282009dd85995d7eea_1467_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/00606-icon-service-Azure-Synapse-Analytics_hu8e9af3290ac174282009dd85995d7eea_1467_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Synapse Analytics&lt;/h3&gt;
&lt;p&gt;Azure Synapse Analytics est avant tout une suite d&amp;rsquo;outils comprenant :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;un outil de type ETL/ELT, qui est simplement une version d&amp;rsquo;Azure Data Factory&lt;/li&gt;
&lt;li&gt;des moteurs de traitements de données :
&lt;ul&gt;
&lt;li&gt;SQL
&lt;ul&gt;
&lt;li&gt;Pools provisionnés : Vous louez des capacités de traitements SQL dédiés.&lt;/li&gt;
&lt;li&gt;Serverless : Vous payez vos traitements SQL à la requête.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Apache Spark : le moteur de traitement de données Apache Spark qui permet de créer des traitements de données fortement scalable. Vous pouvez écrire des traitements dans différents langages (Python/R/Scala/Java) et les exécuter sur la plate-forme Spark.&lt;/li&gt;
&lt;li&gt;Data Explorer : un moteur de traitement spécialisé dans les traitements des logs et des séries temporelles.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;un outil de monitoring&lt;/li&gt;
&lt;li&gt;un espace de création regroupant tous les services ci-dessus.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Azure Synapse Analytics est le service phare de la suite Azure pour les traitements de données.&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/synapse-analytics/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;img10787-icon-service-azure-databrickspng-azure-databricks&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/10787-icon-service-Azure-Databricks.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/10787-icon-service-Azure-Databricks_hu8e9af3290ac174282009dd85995d7eea_1519_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/10787-icon-service-Azure-Databricks_hu8e9af3290ac174282009dd85995d7eea_1519_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Databricks&lt;/h3&gt;
&lt;p&gt;Azure Databricks est l&amp;rsquo;implémentation de Databricks dans Azure.&lt;br&gt;
Databricks est un outil basé sur Apache Spark tout en incluant des services complémentaires. Au même titre qu&amp;rsquo;Azure Synapse Analytics, il permet de créer des traitements d&amp;rsquo;ingestion et de préparation de données.&lt;/p&gt;
&lt;p&gt;Contrairement à Azure Synapse Analytics, Databricks est prévu pour être multicloud, vous retrouverez ce service dans AWS (Amazon) ou GCP (Google).&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/databricks/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;img10145-icon-service-azure-data-explorer-clusterspng-azure-data-explorer&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/10145-icon-service-Azure-Data-Explorer-Clusters.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/10145-icon-service-Azure-Data-Explorer-Clusters_hu8e9af3290ac174282009dd85995d7eea_1395_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/10145-icon-service-Azure-Data-Explorer-Clusters_hu8e9af3290ac174282009dd85995d7eea_1395_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Data Explorer&lt;/h3&gt;
&lt;p&gt;Azure Data Explorer est un moteur de traitement spécialisé dans les traitements des logs et des séries temporelles.&lt;br&gt;
Microsoft a créé un langage de requête dédié nommé KQL (Kusto Query Language) permettant de plonger dans les puits de logs comme le commandant Cousteau dans la mer.&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/data-explorer/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;les-services-cognitifs&#34;&gt;Les services cognitifs&lt;/h2&gt;
&lt;h3 id=&#34;img10162-icon-service-cognitive-servicespng-azure-cognitive-services&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/10162-icon-service-Cognitive-Services.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/10162-icon-service-Cognitive-Services_hu8e9af3290ac174282009dd85995d7eea_1235_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/10162-icon-service-Cognitive-Services_hu8e9af3290ac174282009dd85995d7eea_1235_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Cognitive Services&lt;/h3&gt;
&lt;p&gt;Azure Cognitive Services est un ensemble de service de type IA préentrainé que vous pouvez consommer directement sous forme d&amp;rsquo;API.&lt;br&gt;
Parmi les principaux services proposés, on retrouve :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;La reconnaissance de texte&lt;/li&gt;
&lt;li&gt;La reconnaissance faciale&lt;/li&gt;
&lt;li&gt;La reconnaissance d&amp;rsquo;entité sur des images ou vidéos&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Vous pouvez intégrer ces services dans vos traitements de données pour enrichir ces dernières.&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/cognitive-services/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;img10167-icon-service-machine-learning-studio-workspacespng-azure-machine-learning&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/10167-icon-service-Machine-Learning-Studio-Workspaces.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/10167-icon-service-Machine-Learning-Studio-Workspaces_hu8e9af3290ac174282009dd85995d7eea_868_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/10167-icon-service-Machine-Learning-Studio-Workspaces_hu8e9af3290ac174282009dd85995d7eea_868_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Machine Learning&lt;/h3&gt;
&lt;p&gt;Azure Machine Learning est un outil de création d&amp;rsquo;expérience de Machine Learning, il prend en charge de bout en bout ce type de projet de la création du modèle à son exploitation en production.&lt;br&gt;
Les modèles ainsi créés pourront enrichir vos traitements de données.&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/machine-learning/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;les-services-de-calcul-utilisable-pour-traiter-les-données&#34;&gt;Les services de calcul utilisable pour traiter les données&lt;/h2&gt;
&lt;h3 id=&#34;img10029-icon-service-function-appspng-azure-functions&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/10029-icon-service-Function-Apps.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/10029-icon-service-Function-Apps_hu8e9af3290ac174282009dd85995d7eea_1188_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/10029-icon-service-Function-Apps_hu8e9af3290ac174282009dd85995d7eea_1188_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Functions&lt;/h3&gt;
&lt;p&gt;Azure Functions permet d&amp;rsquo;exécuter du code à la demande dans Azure, sans louer de ressources en permanence. Vous êtes facturé à l&amp;rsquo;usage.&lt;br&gt;
Vous pouvez créer des traitements s&amp;rsquo;exécutant à la demande, sur des évènements Azure ou de manière planifiée.&lt;br&gt;
Les principaux langages disponibles sont :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C#&lt;/li&gt;
&lt;li&gt;JavaScript&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;li&gt;PowerShell&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;TypeScript&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Par défaut les Azure Functions sont limitées à 5 minutes d&amp;rsquo;exécutions, 10 maximum. Si vous avez besoin de plus regarder &lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/en-us/azure/azure-functions/durable/durable-functions-overview?tabs=csharp-inproc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;les fonctions durables.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/functions/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;img10201-icon-service-logic-appspng-azure-logic-apps&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/10201-icon-service-Logic-Apps.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/10201-icon-service-Logic-Apps_hu8e9af3290ac174282009dd85995d7eea_949_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/10201-icon-service-Logic-Apps_hu8e9af3290ac174282009dd85995d7eea_949_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Logic Apps&lt;/h3&gt;
&lt;p&gt;Azure Logic Apps est un outil de création de traitement low code. Il est très proche en termes d&amp;rsquo;interface et d&amp;rsquo;utilisation de Power Automate, mais contrairement à ce dernier vous payez les traitements à l&amp;rsquo;exécution, quels que soient les connecteurs utilisés.&lt;br&gt;
Vous pouvez créer des traitements s&amp;rsquo;exécutant à la demande, sur des évènements Azure ou de manière planifiée.&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/logic-apps/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;autres-services-azure-à-intégrer&#34;&gt;Autres services Azure à intégrer&lt;/h2&gt;
&lt;h3 id=&#34;img10245-icon-service-key-vaultspng-azure-key-vault&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/10245-icon-service-Key-Vaults.png&#34;
	width=&#34;30&#34;
	height=&#34;30&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/10245-icon-service-Key-Vaults_hu7a6ed2925b8411b46ca180016908f0d9_1806_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/10245-icon-service-Key-Vaults_hu7a6ed2925b8411b46ca180016908f0d9_1806_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;100&#34;
		data-flex-basis=&#34;240px&#34;
	
&gt; Azure Key Vault&lt;/h3&gt;
&lt;p&gt;Azure Key Vault est un coffre-fort pour vos mots de passe, est-il besoin de rappeler qu&amp;rsquo;un mot de passe n&amp;rsquo;a rien à faire en clair dans un code ?&lt;br&gt;
Azure Key Vault vous permettra de sécurisé vos mots de passe et autres secrets et le mettra à disposition des applications ayant le droit de les utiliser. Vos différentes briques de services Azure ou autre pourront ainsi utiliser des secrets en toute discrétion.&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/key-vault/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;imgpurviewpng-microsoft-purview&#34;&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/purview.png&#34;
	width=&#34;30&#34;
	height=&#34;19&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/purview_huebae1058d42e27fb2cdbb3964620300c_1234_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/purview_huebae1058d42e27fb2cdbb3964620300c_1234_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;157&#34;
		data-flex-basis=&#34;378px&#34;
	
&gt; Microsoft Purview&lt;/h3&gt;
&lt;p&gt;Microsoft Purview est en ensemble d&amp;rsquo;outils permettant de mettre en place une gouvernance de données globale. Il vous permet aussi de mettre en place un catalogue de données d&amp;rsquo;entreprise.&lt;/p&gt;
&lt;p&gt;Vous retrouverez les informations sur le produit &lt;a class=&#34;link&#34; href=&#34;https://azure.microsoft.com/fr-fr/products/purview/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;architecture-type&#34;&gt;Architecture type&lt;/h2&gt;
&lt;p&gt;Tous les outils présentés ci-dessus peuvent travailler ensemble dans des architectures data moderne, ma préférée étant celle autour de Synapse pour un usage BI:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-compute/img/enterprise-bi-scoped-architecture.png&#34;
	width=&#34;1200&#34;
	height=&#34;846&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-compute/img/enterprise-bi-scoped-architecture_hu1f3b34477e815894fea8669db0f97484_250544_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-compute/img/enterprise-bi-scoped-architecture_hu1f3b34477e815894fea8669db0f97484_250544_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Décisionnel d’entreprise&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;Vous trouverez les références de cette architecture &lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/fr-fr/azure/architecture/example-scenario/analytics/enterprise-bi-synapse&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt; et une version plus globale &lt;a class=&#34;link&#34; href=&#34;https://learn.microsoft.com/fr-fr/azure/architecture/example-scenario/dataplate2e/data-platform-end-to-end&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ici&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Merci de votre attention.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Datalake : la base d&#39;un projet data moderne</title>
        <link>https://blog.ddata.fr/p/datalake-la-base/</link>
        <pubDate>Sun, 26 Feb 2023 00:00:00 +0000</pubDate>
        
        <guid>https://blog.ddata.fr/p/datalake-la-base/</guid>
        <description>&lt;img src="https://blog.ddata.fr/p/datalake-la-base/ticka-kao-o87vASD6Ksk-unsplash.jpg" alt="Featured image of post Datalake : la base d&#39;un projet data moderne" /&gt;&lt;p&gt;Dans cet article je vous présente le concept de Datalake ou lac de données en bon français. Un datalake est la fondation d&amp;rsquo;un projet data moderne, vous le retrouverez dans la plupart de vos futurs projets.&lt;/p&gt;
&lt;h2 id=&#34;contexte&#34;&gt;Contexte&lt;/h2&gt;
&lt;p&gt;Comme je vous l&amp;rsquo;ai présenté &lt;a class=&#34;link&#34; href=&#34;https://blog.ddata.fr/p/reporting-datawarehouse-datalakehouse/&#34; &gt;dans ce précédent article&lt;/a&gt;, le datalake est un élément clé des projets data moderne. Je me propose maintenant de vous présenter plus en détail ce qu&amp;rsquo;est un datalake, comment on le structure et comment on peut s&amp;rsquo;en servir.&lt;br&gt;
Contrairement à ce que l&amp;rsquo;on pourrait croire, les datalakes ne sont pas réservés aux gros projets de data et leur philosophie d&amp;rsquo;usage peut-être reprise dans tout projet data.&lt;/p&gt;
&lt;h2 id=&#34;le-stockage&#34;&gt;Le stockage&lt;/h2&gt;
&lt;p&gt;Lorsque l&amp;rsquo;on parle datalake on parle avant tout d&amp;rsquo;un stockage de données pouvant accepter tout type de format de données.&lt;br&gt;
En général lorsque l&amp;rsquo;on parle de datalake on pense stockage cloud, l&amp;rsquo;avantage de ce type de stockage est sa capacité à être étendue en fonction de vos besoins et de vos finances. Bien que cette solution est la plus souple, on peut très bien créer un datalake en dehors du cloud.&lt;br&gt;
Les principaux types de stockages pour vos datalakes peuvent être :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;En cloud dans l&amp;rsquo;écosystème Microsoft
&lt;ul&gt;
&lt;li&gt;Azure Datalake Gen 2&lt;/li&gt;
&lt;li&gt;Sharepoint&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sur vos infrastructures locales
&lt;ul&gt;
&lt;li&gt;Un partage réseau&lt;/li&gt;
&lt;li&gt;Un disque dur&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lorganisation&#34;&gt;L&amp;rsquo;organisation&lt;/h2&gt;
&lt;p&gt;Une fois la solution de stockage choisie, il est indispensable de réfléchir à l&amp;rsquo;organisation de votre datalake.&lt;br&gt;
Sans rigueur votre lac de données deviendra un marais de données (dataswamp).&lt;/p&gt;
&lt;h3 id=&#34;les-zones&#34;&gt;Les zones&lt;/h3&gt;
&lt;p&gt;Bien que chacun puisse créer l&amp;rsquo;organisation qu&amp;rsquo;il souhaite, on retrouve en général les 3 zones suivantes :&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-la-base/img/001-datalake-zone.png&#34;
	width=&#34;799&#34;
	height=&#34;230&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-la-base/img/001-datalake-zone_hu727fac40be1e93915e54196ea9c46c88_7320_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-la-base/img/001-datalake-zone_hu727fac40be1e93915e54196ea9c46c88_7320_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Les zones d&amp;rsquo;un datalake&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;347&#34;
		data-flex-basis=&#34;833px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bronze : Cette zone sert de landing zone pour les données, elle permet d&amp;rsquo;écrire les données brutes reçues dans le datalake. Aucune transformation n&amp;rsquo;est réalisée sur les données.&lt;/li&gt;
&lt;li&gt;Silver : cette zone permet de raffiner les données de la zone Bronze et d&amp;rsquo;effectuer les traitements de préparation de données parmi lesquels on retrouve :
&lt;ul&gt;
&lt;li&gt;La transformation de données en un format de table avec
&lt;ul&gt;
&lt;li&gt;Le nommage des colonnes&lt;/li&gt;
&lt;li&gt;Le typage des colonnes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;La détection des anomalies&lt;/li&gt;
&lt;li&gt;La détection des problèmes de qualité&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gold : cette zone contient les données avec le plus haut niveau de raffinage, on retrouve par exemple
&lt;ul&gt;
&lt;li&gt;Des données modélisées pour le reporting (modèle en étoile).&lt;/li&gt;
&lt;li&gt;Des données préaggrégées.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Le nom de ces zones peut varier, mais leur usage reste. D&amp;rsquo;autres zones peuvent être créées en fonction de vos besoins spécifiques, par exemple une zone sandbox pour des expérimentations.&lt;/p&gt;
&lt;p&gt;Les coûts de stockage étant relativement bas, en général, les traitements permettant le raffinage des données d&amp;rsquo;une zone à l&amp;rsquo;autre ne suppriment pas les données traitées. Ainsi si vous traitez des données sources en utilisant 10 champs sur 50 dans le fichier brut et que vos besoins évoluent, vous aurez toujours la possibilité de retraiter l&amp;rsquo;ensemble des données brut pour répondre à vos nouveaux besoins.&lt;/p&gt;
&lt;h3 id=&#34;les-partitions&#34;&gt;Les partitions&lt;/h3&gt;
&lt;p&gt;Le partitionnement des données va vous permettre de ranger vos données de manière précise. Quand on parle de partitionnement, il s&amp;rsquo;agit simplement de mettre vos fichiers dans des dossiers et sous dossier différent. L&amp;rsquo;avantage du partitionnement est notamment de pouvoir accéder rapidement à des données en ne lisant que les fichiers présents dans les partitions qui nous intéressent.&lt;br&gt;
Vous pouvez mixer les partitions comme vous le souhaitez.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blog.ddata.fr/p/datalake-la-base/img/002-datalake-partition.png&#34;
	width=&#34;774&#34;
	height=&#34;436&#34;
	srcset=&#34;https://blog.ddata.fr/p/datalake-la-base/img/002-datalake-partition_hu0016a9332b0f3ada4911fd5db105c496_15833_480x0_resize_box_3.png 480w, https://blog.ddata.fr/p/datalake-la-base/img/002-datalake-partition_hu0016a9332b0f3ada4911fd5db105c496_15833_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Exemple de partitions&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;177&#34;
		data-flex-basis=&#34;426px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;En général, on crée des partitions en créant des  dossiers sous la forme &lt;em&gt;NomPartition=ValeurPartition&lt;/em&gt;.&lt;br&gt;
Les principaux partitionnements que vous utiliserez sont :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Par source de données avec par exemple des dossiers sous la forme &lt;em&gt;/service=rh/application=monapplication&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Par version de traitement ou de format de fichier avec par exemple des dossiers sous la forme &lt;em&gt;/version=2.0&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Par date avec par exemple des dossiers sous la forme &lt;em&gt;/year=2023/month=02/day=26&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;les-principaux-formats-de-données&#34;&gt;Les principaux formats de données&lt;/h2&gt;
&lt;p&gt;Votre datalake va contenir des fichiers, voici quelque format classique que vous y trouverez :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parquet : C&amp;rsquo;est le format roi des datalakes, il s&amp;rsquo;agit d&amp;rsquo;un format de fichier dédier aux données analytiques, il conserve le nom et le type de données des colonnes et compresse les données contenues dans le fichier.&lt;/li&gt;
&lt;li&gt;CSV : Format classique d&amp;rsquo;extraction de données, il contient le nom des colonnes, mais les séparateurs utilisés peuvent varier en fonction de l&amp;rsquo;origine régionale du fichier (les séparateurs US et FR sont différents).&lt;/li&gt;
&lt;li&gt;Excel : Est-ce besoin de le présenter ? Un incontournable dans tous projets data.&lt;/li&gt;
&lt;li&gt;json, yaml, xml : Il s&amp;rsquo;agit en général de fichiers issus de traitement automatisé tel des API. Ces fichiers sont semi-structuré.&lt;/li&gt;
&lt;li&gt;log : les fichiers de log pourront être stockés longtemps et conserver une possibilité de traitement dans un datalake. Ces fichiers sont en général semi-structuré.&lt;/li&gt;
&lt;li&gt;Binaire : les vidéos et images sont des formats de données binaires, ils peuvent contenir certaines métadonnées exploitables directement (coordonnée GPS pour une photo par exemple), mais en général un traitement de type IA et nécessaire pour qualifier le contenu du fichier.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;la-sécurité&#34;&gt;La sécurité&lt;/h2&gt;
&lt;p&gt;La sécurité est un point clé de votre datalake, elle est portée par les possibilités offertes par la solution de stockage que vous avez choisie.&lt;br&gt;
Dans tous les cas, penser à créer plusieurs datalakes si vous avez des besoins forts de sécurité, une séparation des données peut prémunir contre des niveaux de droits inadéquats accordés à certain utilisateur.&lt;/p&gt;
&lt;h2 id=&#34;traitement-des-données&#34;&gt;Traitement des données&lt;/h2&gt;
&lt;p&gt;Le traitement des données d&amp;rsquo;un datalake fera l&amp;rsquo;objet d&amp;rsquo;un prochain article.&lt;/p&gt;
&lt;p&gt;Merci de votre attention.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Cékoidonc Azure ?</title>
        <link>https://blog.ddata.fr/p/c%C3%A9koidonc-azure/</link>
        <pubDate>Thu, 11 Aug 2022 00:00:00 +0000</pubDate>
        
        <guid>https://blog.ddata.fr/p/c%C3%A9koidonc-azure/</guid>
        <description>&lt;img src="https://blog.ddata.fr/p/c%C3%A9koidonc-azure/adrien-olichon-KzkIVT1HCVY-unsplash.jpg" alt="Featured image of post Cékoidonc Azure ?" /&gt;&lt;p&gt;Cékoidonc Azure ?&lt;/p&gt;
&lt;p&gt;Lorsque vous affichez cette page de blog, cela n&amp;rsquo;est ni magique ni divin. Vous faites appel à des services informatiques qui répondent à votre demande.&lt;br&gt;
Ces services peuvent être de nature différente, mais ont tous en commun d&amp;rsquo;être disponible sur Internet.&lt;br&gt;
Il existe des fournisseurs qui vous louent des services informatiques sur Internet, c&amp;rsquo;est ce que l&amp;rsquo;on appelle le cloud.&lt;br&gt;
Parmi ces fournisseurs on retrouve :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Amazon avec le service AWS (Amazon Web Services).&lt;/li&gt;
&lt;li&gt;Microsoft avec le service Azure.&lt;/li&gt;
&lt;li&gt;Google avec le service GCP (Google Cloud Platform).&lt;/li&gt;
&lt;li&gt;OVH avec le service OCHcloud.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Azure est donc un service de location de ressources informatique sur Internet délivré par Microsoft.&lt;br&gt;
Azure propose plus de 200 types de services différents à la location.&lt;/p&gt;</description>
        </item>
        <item>
        <title>Cékoidonc Azure Active Directory ?</title>
        <link>https://blog.ddata.fr/p/c%C3%A9koidonc-azure-active-directory/</link>
        <pubDate>Thu, 11 Aug 2022 00:00:00 +0000</pubDate>
        
        <guid>https://blog.ddata.fr/p/c%C3%A9koidonc-azure-active-directory/</guid>
        <description>&lt;img src="https://blog.ddata.fr/p/c%C3%A9koidonc-azure-active-directory/jukebox-print-FUohNQatzVs-unsplash.jpg" alt="Featured image of post Cékoidonc Azure Active Directory ?" /&gt;&lt;p&gt;Cékoidonc Azure Active Directory ?&lt;/p&gt;
&lt;p&gt;Lorsque vous souscrivez à des services en ligne, vous ne souhaitez que n&amp;rsquo;importe qui accède à vos ressources, on parle dans ce cas d&amp;rsquo;authentification des utilisateurs.&lt;br&gt;
Parmi vos utilisateurs authentifiés, vous ne voulez pas non plus que tout le monde accède à tout, on parle dans ce cas d&amp;rsquo;autorisations.&lt;/p&gt;
&lt;p&gt;Azure Active Directory est le service Azure en charge de l&amp;rsquo;authentification.&lt;br&gt;
La gestion des autorisations des services Azure, sera réalisé sur les utilisateurs authentifiés dans Azure Active Directory.&lt;/p&gt;
&lt;p&gt;On utilise souvent les acronymes Azure AD ou AAD pour Azure Active Directory.&lt;/p&gt;
&lt;p&gt;En plus des utilisateurs, AAD permet de gérer des groupes, dans lesquels on ajoute des utilisateurs. Un utilisateur peut être membre de plusieurs groupes.&lt;br&gt;
La bonne pratique est d&amp;rsquo;affecter les droits à des groupes et non à des utilisateurs individuellement, ainsi c&amp;rsquo;est plus simple d&amp;rsquo;affecter des droits à un nouvel utilisateur en le rendant simplement membre des groupes correspondants au besoin.&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
